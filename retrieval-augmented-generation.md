## Retrieval Augmented Generation

[![What is Retrieval-Augmented Generation (RAG)? (6 min)](https://i.ytimg.com/vi_webp/T-D1OfcDW1M/sddefault.webp)](https://youtu.be/T-D1OfcDW1M)

Watch the walkthrough above, then dive into the notebook for step-by-step practice.

You will learn to implement Retrieval Augmented Generation (RAG) to enhance language models' responses by incorporating relevant context, covering:

- **LLM Context Limitations**: Understanding the constraints of context windows in large language models.
- **Retrieval Augmented Generation**: The technique of retrieving and using relevant documents to enhance model responses.
- **Embeddings**: How to convert text into numerical representations that are used for similarity calculations.
- **Similarity Search**: Finding the most relevant documents by calculating cosine similarity between embeddings.
- **OpenAI API Integration**: Using the OpenAI API to generate responses based on the most relevant documents.
- **Tourist Recommendation Bot**: Building a bot that recommends tourist attractions based on user interests using embeddings.
- **Next Steps for Implementation**: Insights into scaling the solution with a vector database, re-rankers, and improved prompts for better accuracy and efficiency.

Here are the links used in the video:

- [Jupyter Notebook](https://colab.research.google.com/drive/1x-g0kjktFkBcujJssKrx1xhZarsQA0ya)
- [`gte-large-en-v1.5` embedding model](https://huggingface.co/Alibaba-NLP/gte-large-en-v1.5)
- [Awesome vector database](https://github.com/mileszim/awesome-vector-database)
