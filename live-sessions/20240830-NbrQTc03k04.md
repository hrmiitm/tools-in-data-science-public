# TA Session 29th August: Revision: Modules 7 to 9, CSS selectors, Javascript

[![TA Session 29th August: Revision: Modules 7 to 9, CSS selectors, Javascript](https://i.ytimg.com/vi_webp/NbrQTc03k04/sddefault.webp)](https://youtu.be/NbrQTc03k04)

Duration: 1h 25m

Here's an FAQ summary of the tutorial:

**Q1: What should I expect from the TDS end-term exam?**

**A1:** The end-term exam will have between 40 to 60 questions, which should be fairly quick to answer with no complex math involved. I suggest completing the TDS paper first, as you can breeze through it rapidly. Don't leave any questions unanswered; try to mark something for every question, as they will be either MCQ or MSQ format. You should be able to finish in about 30-35 minutes, leaving you plenty of time for other subjects.

**Q2: What modules will the end-term exam cover?**

**A2:** We'll be covering modules 7, 8, and 9. There are also likely to be questions on HTML and CSS, specifically CSS selectors. While I can't guarantee it, we've been asked to tell students to prepare for these topics.

---

### Module 7: Designing Your Output

**Q3: What general Excel tools are important for designing output?**

**A3:** You're expected to be familiar with Excel's basic functions and how to use them to generate designed output. Specific tools to know include:

- `FORECAST.ETS`: This function helps visualize data and forecast future values based on historical data. It's particularly good for time series data. You need to remember its syntax and parameters.
- Filters, Pivot Tables, Ranges, Sparklines: These are essential for organizing and presenting data effectively.
- Standard Deviation and Correlation functions (`STDEV.S`, `CORREL`).
- Growth function (similar to `FORECAST.ETS`).

**Q4: Can you explain the `FORECAST.ETS` function in more detail?**

**A4:** `FORECAST.ETS` helps predict future values. It takes three required parameters and three optional ones:

- **Target Date:** The specific date for which you want a prediction.
- **Historic Values:** The range of past data points you're using for the forecast.
- **Timeline:** The corresponding dates for your historic values. These two (historic values and timeline) usually go together, with one on each axis of a chart.

**Q5: What are the optional parameters for `FORECAST.ETS`?**

**A5:** The optional parameters help refine the forecast, and usually default to '1':

- **Seasonality:** If your data shows seasonal patterns (e.g., sales going up and down at certain times), Excel will use this to make forecasts that match those patterns. You can turn this off by using '0'.
- **Data Completion:** This allows Excel to fill in missing data points (up to 30% of the dataset) by finding the average between two surrounding points.
- **Aggregation:** If your timeline has duplicate dates with multiple entries, aggregation determines how these values are combined (e.g., by averaging them).

**Q6: How can I learn more about `FORECAST.ETS` and other Excel functions for the exam?**

**A6:** You can look up `FORECAST.ETS` (and other functions) in Google or directly in Excel's help menu. The online Microsoft help is particularly useful as it often includes a worksheet demonstrating how the function works. I highly recommend watching the video "Visualizing Forecast with Excel" as it beautifully explains how to derive things like variance, use sparklines, and convert dates to integers for forecasting. The exam won't ask you to perform calculations, but they might ask you to identify the correct formula or process.

**Q7: What is the significance of converting a date to an integer in Excel?**

**A7:** When you convert a date to an integer in Excel, it represents the number of days since January 1, 1900. This conversion is necessary for certain functions like forecasting that require integer values for calculations.

**Q8: What are sparklines and how do I create them in Excel?**

**A8:** Sparklines are small charts within a single cell that visualize trends in data. To create one, go to Insert > Sparklines > Line.

**Q9: What are the primary uses of different chart types in Excel?**

**A9:** Understanding the purpose of various charts is important:

- **Bar Charts:** Used for comparing categorical data.
- **Line Charts:** Primarily used for identifying trends over time.
- **Pie Charts:** Best for showing proportions or parts of a whole.
- **Histograms:** Used to visualize the distribution of a numerical value.
- **Heat Maps:** Ideal for seeing the magnitude of data across two dimensions or for correlation visualization.
- **Tree Maps:** Used to represent hierarchical data.

**Q10: What are general Business Intelligence (BI) tools, and what are some examples?**

**A10:** BI tools are used for reporting and data visualization to provide insights. Examples include:

- Google Data Studio
- Power BI
- Tableau

**Q11: What is the difference between Tableau (a BI tool) and Tabula (a Python library)?**

**A11:** This is a common point of confusion. Tableau is a full-fledged BI tool used for data visualization and analysis. Tabula is a Python library specifically used for PDF scraping. It's important to differentiate them for exam questions.

**Q12: What should I know about Power BI for the exam, even if I don't have access to it?**

**A12:** While Power BI is generally a paid software, you should watch the relevant video and be familiar with its capabilities. For instance, Power BI is known for its ability to generate charts from a text description, almost like an LLM.

**Q13: What are specialized tools for output visualization?**

**A13:** Beyond general BI tools, there are specialized options:

- **Flourish:** Used for creating animated charts. It can import various data formats like Excel, CSV, TSV, JSON, GeoJSON, and connect to Google Sheets or URLs.
- **Kumu:** Primarily used for network visualization. When importing data, it's crucial to have 'from' and 'to' fields to establish relationships, and you can add 'weights' to these relationships.
- **QGIS:** Used for geographic visualizations.

---

### Module 8: Data Storytelling

**Q14: What is data storytelling and what are its key components?**

**A14:** Data storytelling is the practice of translating data analysis into a compelling and easy-to-understand narrative for your audience. Its components are:

- **Data:** Provides the facts and figures.
- **Visuals:** Charts, graphs, and images that support the narrative and make data easier to interpret.
- **Narrative:** The storyline that connects the data with the visuals, providing context and insight.

**Q15: What are some effective storytelling techniques for presenting data?**

**A15:** Some common techniques include:

- **Hero's Journey:** A narrative structure where a hero (your data) faces challenges, overcomes them, and achieves a conclusion.
- **Contrast and Comparison:** Highlighting differences or similarities in data to make a point.
- **Cause and Effect:** Showing how one event or variable influences another.
- **Trends and Behaviors:** Illustrating patterns and changes over time.

**Q16: What tools can I use for data storytelling and storyboarding?**

**A16:**

- **Data Storytelling Tools:** BI tools like Tableau and Power BI, and Python libraries like Plotly, Matplotlib, Seaborn, and Dash.
- **Storyboarding Tools:** Canva, PowerPoint, Google Slides, and Keynote are good for creating visual outlines.
- **Narrative Building Tools:** Jupyter Notebooks are excellent, as they allow you to combine code, output, and rich markdown cells to create a comprehensive narrative.

**Q17: What are common pitfalls to avoid when creating data stories?**

**A17:** Be mindful of these challenges:

- **Overloading People with Data:** Presenting too much information can overwhelm your audience.
- **Misleading Narratives:** Ensuring your story accurately represents the data is crucial for ethical practice.
- **Ignoring the Audience:** Failing to tailor your story to the specific needs, technical understanding, and concerns of your audience can make your insights irrelevant or inaccessible.

---

### Module 9: Deployment

**Q18: What is deployment in the context of data science?**

**A18:** Deployment is the process of integrating your data science model or application into an operational environment where it can be accessed and used by various end-users. A "deployment pipeline" refers to the series of steps to move your model from your local machine to a place where others can interact with it.

**Q19: What tools are available for anonymizing data before deployment?**

**A19:** Tools like ARX and Amnesia can be used to anonymize data. You should also be aware of the `faker` and `mimesis` Python libraries, which can generate fake data, another way to anonymize sensitive information.

**Q20: How do you build apps for deployment, and what platforms are used for hosting?**

**A20:**

- **App Building Environments:** You can build apps using notebooks like Colab or Kaggle.
- **Data Apps:** Frameworks like Streamlit and Shiny simplify creating interactive web applications for data.
- **Web Apps:** More traditional web frameworks include Flask and Tornado.
- **Hosting Platforms (Cloud Platforms):**
  - **Infrastructure-based:** AWS (Amazon Web Services), Google Cloud Platform (GCP), Microsoft Azure.
  - **App-hosting:** Heroku, Glitch (these focus more on deploying the application itself rather than raw infrastructure).

**Q21: What are the main challenges when deploying a data science model?**

**A21:** Key challenges include:

- **Scalability:** Ensuring your deployment can handle increasing numbers of users and data volume.
- **Security:** Protecting the model, data, and user information from unauthorized access, including compliance with data privacy regulations (which is very crucial).
- **Latency:** Minimizing the time it takes for your model to generate an output after receiving an input (especially critical for real-time applications).
- **Integration:** Making sure your model works well with existing systems and data sources in your production environment.

---

### HTML and CSS Review

**Q22: What specific HTML/CSS topics should I review for the exam?**

**A22:** You should review HTML and CSS, with a strong emphasis on CSS selectors. I highly recommend spending time preparing for them, as they are very likely to appear on the exam. There was a dedicated session on CSS selectors, and the MDN Web Docs are an excellent resource for this.

**Q23: Can you explain some fundamental CSS selectors?**

**A23:** Understanding these basic selectors is crucial:

- **Type Selector (e.g., `p` for paragraphs):** Selects all elements of a specific HTML tag.
- **Class Selector (e.g., `.myclass`):** Selects elements with a specific class attribute (preceded by a dot).
- **ID Selector (e.g., `#myid`):** Selects a unique element with a specific ID (preceded by a hash `#`).
- **Universal Selector (e.g., `*`):** Selects all elements.
- **Grouping Selector (e.g., `h1, p`):** Selects multiple elements by separating them with a comma.
- **Descendant Combinator (e.g., `div p`):** Selects all `<p>` elements that are descendants (children, grandchildren, etc.) of a `<div>` element (space between selectors).
- **Child Combinator (e.g., `div > p`):** Selects only direct children of an element (using `>`).
- **Attribute Selector (e.g., `a[href]`, `a[href="example.com"]`):** Selects elements based on their attributes or attribute values.
- **Pseudo-classes (e.g., `:hover`, `:first-child`, `:last-child`):** Select elements based on their state or position within the document tree.
- **Pseudo-elements (e.g., `::before`, `::after`):** Selects a part of an element rather than the entire element.

**Q24: What JavaScript concepts are important for the exam, especially for web scraping?**

**A24:** From the Week 2 JavaScript video, specifically review:

- The `copy()` function.
- The `$$()` function (equivalent to `document.querySelectorAll()`, which uses CSS selectors).
- How to construct various queries using CSS selectors for web scraping.
- The ternary operator.
- The `querySelector()` function.

---

### General Exam Advice & Resources

**Q25: What are the recommended resources for CSS selectors and other topics?**

**A25:**

- **CSS Selectors:** MDN Web Docs is highly recommended. It explains selectors fantastically, including type, class, ID, attributes, pseudo-classes, combinators, and pseudo-elements. W3Schools is also a good resource.
- **Specific Videos:** I've recommended watching "Visualizing Forecast with Excel" and the Power BI video.
- **Instructor's File:** I will share the review file (with my squiggles!) on Discord, and might add some more detailed points.
- **Recordings:** The recording of this session will be available on the portal by tomorrow afternoon.

**Q26: Are all weeks equally weighted in the end-term exam?**

**A26:** Yes, it is my understanding that all weeks (and topics) have equal probability for questions; there is no skewness.

**Q27: Can I get access to the recording or a PDF of today's session?**

**A27:** Yes, the recording will be uploaded to the portal by tomorrow afternoon. I will also share the PDF of my notes (even with the squiggles!) on Discord, potentially with some added details.

**Q28: Why do you suggest we focus on understanding certain tools or functions rather than performing calculations?**

**A28:** For the end-term exam, the focus is on your conceptual understanding of what various tools and functions _do_ and _how they are structured_, rather than your ability to perform complex calculations. This is because we acknowledge that not all students have hands-on access to all software (like Power BI or Tableau) or extensive coding practice, and the exam aims to assess your knowledge of the broader data science landscape. Therefore, understanding the workflow, parameters, and use cases is key.
