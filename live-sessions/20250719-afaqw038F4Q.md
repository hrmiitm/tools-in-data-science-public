# 2025 07 18 MOCK ROE  session 4 - TDS May 2025

[![2025 07 18 MOCK ROE  session 4 - TDS May 2025](https://i.ytimg.com/vi_webp/afaqw038F4Q/sddefault.webp)](https://youtu.be/afaqw038F4Q)

Duration: 2h 7m

Here is the FAQ from the Tools in Data Science live tutorial.

### **General & Logistical Questions**

**Q1: Will a recording of this session be available later?**

**A1:** Yes, the recording will be uploaded for you to watch later.

**Q2: What AI tool do you recommend for the exam: ChatGPT, Perplexity, or Copilot?**

**A2:** I find Copilot to be the most helpful. It has context for all the files in your project, which is a big advantage over a tool like ChatGPT where you might have to manually paste data from CSVs or other files to give it context.

**Q3: What's the recommended setup for the exam environment? Should I use a Linux terminal?**

**A3:** Using Linux, for example through WSL (Windows Subsystem for Linux), is much faster and highly recommended. Copilot also tends to generate code that is more compatible with Linux. While you can use Windows, you might need to make small adjustments to the code. Also, make sure you have Copilot installed and ready to go.

**Q4: Is Docker required for the exam?**

**A4:** No, you won't need Docker for this exam. It's a bit heavy to set up and use in a timed environment.

**Q5: The submission buttons on the mock test page are disabled for me. How can I fix this?**

**A5:** That's happening because the mock is from a previous term and its deadline has passed. You can easily re-enable the buttons yourself. Just right-click the "Check" button, choose "Inspect," find the `disabled` attribute in the HTML code, and delete it. You can do this for both individual question buttons and the "Check All" button.

**Q6: What’s a good way for our group to collaborate during the exam?**

**A6:** Using a shared GitHub repository is a great idea. You can add your team members as collaborators, which allows everyone to push code directly without needing pull requests. This is faster for sharing solutions. Just create a public repo, go to `Settings > Collaborators`, and add your teammates. A shared Google Doc also works well for quickly pasting code and prompts.

### **Exam Strategy**

**Q7: Some questions require writing a lot of code from scratch. What's the best strategy to solve them quickly?**

**A7:** Using an AI tool like Copilot is your best bet. I used it for most of these questions. A good approach is to start with the easier questions first—like ones involving simple JSON manipulation or a correlation calculation in Pandas—to build momentum. Then, tackle the harder ones. Also, remember that some questions might be very similar to previous graded assignments, so you can adapt code you've already written.

**Q8: What should I do if I get stuck on a difficult question?**

**A8:** Don't spend too much time on a single problem. If you try an approach once or twice and it doesn't work, move on to another question. You can always come back to it later if you have time. The key is to solve as many questions as you can.

**Q9: For questions that need a running server, like with FastAPI, what's the best way to manage that?**

**A9:** A good practice is to keep the server running in a terminal in the background for the whole exam. If you have multiple questions that require a server, you can simply run each one on a different port (e.g., one on port 8000, another on 8001).

**Q10: How can I make the code I generate reusable for my teammates?**

**A10:** Try to make your scripts generic. Instead of hardcoding filenames or other parameters, write your scripts to accept them as command-line arguments. For example, your script could be run like `python your_script.py input_file.zip`. This way, your teammates can use the exact same script just by passing in their own unique files.

### **Specific Question Help**

**Q11: How should I approach Question 1, which asks to create a FastAPI server to get a URL's header?**

**A11:** You'll need to import `FastAPI` to create the server, `uvicorn` to run it, and a library like `httpx` to make an HTTP request from your server to the URL that is passed in. Your API endpoint will receive the URL, use `httpx` to send a GET request to it, and then return the headers from the response.

**Q12: I'm getting a "failed to fetch" or CORS error with my FastAPI app. How do I solve this?**

**A12:** This is a very common issue. You need to enable Cross-Origin Resource Sharing (CORS) in your FastAPI application. I recommend keeping a prompt ready for your AI assistant like, "Always add CORS to any API that needs to be created." This will add the necessary middleware to your app to allow the browser to communicate with your server.

**Q13: For Question 2, involving the Stack Overflow API, what's the best way to get the correct answer?**

**A13:** This question is tricky because it depends on specific documentation. The best approach is to give your AI assistant the documentation provided in the question. I copied the documentation text and the question itself and asked it to generate a script that calls the API and finds the answer, making sure it used the correct endpoint for "related" questions.

**Q14: How should I handle Question 5, which involves analyzing a CSV file?**

**A14:** For questions involving data files, you need to give your AI tool context. I provide it with the first few rows of the CSV file, including the header. This helps it understand the data structure, column names (like `Hour`, `Clothing`, `Electronics`), and data types, which allows it to generate the correct analysis code.

**Q15: For Question 6, my script generates an incorrect SHA hash, and it's the same wrong hash every time. What's wrong?**

**A15:** This is expected! The input zip file is unique for every student, based on your email ID. So, my correct answer will be different from yours. Your script's logic is likely correct, but it's hashing a different set of files. The key steps in the logic are: extracting the zip file, finding all the files (including those in subdirectories), sorting them alphabetically by name, calculating the SHA256 hash of each file's content, concatenating all those hashes into one long string, and finally, calculating the SHA256 hash of that final string.

**Q16: For Question 7 on LLM embeddings, what's the correct way to structure the API request?**

**A16:** The question shows you exactly how the request body should be structured for the text embedding API. It's a JSON object with a key named `input`, which contains the text you want to get an embedding for. Just copy that structure.

**Q17: How should I approach Question 8, which is about finding which franchise a location belongs to?**

**A17:** This problem can be solved using the concept of a "convex hull," which creates a polygon that encloses a set of points. For each franchise, you can create a polygon that encloses all of its store locations. Then, for each new request location, you check which franchise's polygon it falls inside. Since the data is large, I provided the AI with the HTML table structure from the question page to help it understand the input format.

**Q18: You mentioned you can sometimes "hack" the answers. Can you explain that?**

**A18:** "Hacking" is a strong word, but when I'm really stuck, I use the browser's developer tools. I go to the "Sources" tab and find the JavaScript code for the question. This code often contains the logic for both generating the question and checking the answer. I copy this code and give it to an AI like Copilot or Claude, asking it to analyze the logic and determine the correct answer. It can sometimes be faster than debugging the problem statement itself.
